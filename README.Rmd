---
output: github_document
bibliography: report/UFC_Judge_Scoring.bib
---

# UFC Judge Scoring Analysis
Contributors: DSCI 522 Group 513

[Project repository](https://github.com/UBC-MDS/DSCI522_group315)


A data analysis project for DSCI 522 (Data Science workflows). 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(kableExtra)
library(tidyverse)
```

## Introduction

In this project, we are trying to identify the key predictors for win in UFC events and examine whether these key predictors are in line with the UFC official rules. This analysis is very significant because it may serve as a quality control approach for the UFC judging system and also help to improve the rules and training strategies for the judges in the future.

The original data was obtained from Kaggle user [Rajeev Warrier](https://www.kaggle.com/rajeevw) [@UFC-dataset]. The data has also been downloaded and uploaded to a [GitHub repo](https://github.com/SamEdwardes/ufc-data) to avoid issues for users who do not have Kaggle accounts. Each row in the dataset represents statistics from an UFC event, including the performance features and winners (Red or Blue). The data was pre-processed by only selecting the features related to fight performance and for the each feature, the ratio of Blue fighter versus the Red fighter was calculated. The target was computed as whether the Blue fighter won or not. 

We built a regression model using the logistic regression algorithm to assign weights to features and used recursive feature elimination (RFE) approach with cross validation to identify the strong predictors. Among the selected 11 features by RFE, 7 features are related to Striking/Grappling performance which should be considered as the top criteria in judgment based on the UFC official rules [@MMA-judging-criteria]. Our final logistic regression model using these selected features performed well on validation data set with accuracy score of 0.83. It correctly predicted 368 out of 446 test cases and incorrectly predicted 78 cases with 40 being false positive and 38 false negative. Our results showed that the judges generally complied to the UFC rules and put weights on some additional factors.


## Report

The final report can be found [here](report/report.md).

## Usage

To replicate the analysis, you can clone this GitHub repository and install the [dependencies](#dependencies). Then you can run the following command in the terminal from the root directory of this project:

```
make all
```
To remove all the anlaysis and retore the repo to a clean state, you can run the following command in the terminal from the root directory of this project:

```
make clean
```


## Dependencies
- Python 3.7.3 and Python packages:
  - docopt==0.6.2
  - requests==2.22.0
  - pandas==0.24.2
  - numpy==1.16.4
  - altair==3.2.0
  - matplotlib==3.1.0
  - selenium==3.141.0
  - scikit-learn=0.22.1

- chromedriver-binary==80.0.3987.16.0

Note: Users may have an issue producing altair plots. You may need to download the latest version of ChromeDriver.Instructions for installing chromeDriver:
  ```
  conda install selenium
  conda install -c conda-forge python-chromedriver-binary
  ```
  You need to include the ChromeDriver location in your system PATH. Please follow the instructions [here](https://www.kenst.com/2015/03/including-the-chromedriver-location-in-macos-system-path/) for mac users and [here](https://www.google.com/search?q=Including+the+ChromeDriver+location+in+PC&oq=Including+the+ChromeDriver+location+in+PC&aqs=chrome..69i57j69i60l2.2395j0j7&sourceid=chrome&ie=UTF-8) for PC users.
  
  
- R version 3.6.1 and R packages:
  - docopt==0.6.1
  - tidyverse==1.3.0
  - janitor==1.2.0
  - GGally==1.4.0
  - kableExtra==1.1.0
  - knitr==1.27.2
  - testthat == 2.2.1
  - tidyselect == 1.1.0

  
## References